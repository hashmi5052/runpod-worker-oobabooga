FROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04

ARG OOBABOOGA_COMMIT=2af7e382b121f2eae16dd1f7ace621d31028b319
ARG MODEL1="TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ"
ARG MODEL2="ehartford/WizardLM-33B-V1.0-Uncensored"
ARG MODEL3="cognitivecomputations/dolphin-2.1-mistral-7b"

ENV DEBIAN_FRONTEND=noninteractive \
    PIP_PREFER_BINARY=1 \
    PYTHONUNBUFFERED=1

SHELL ["/bin/bash", "-o", "pipefail", "-c"]

RUN apt update && \
    apt upgrade -y && \
    apt install -y \
      python3-dev \
      python3-pip \
      git \
      git-lfs && \
    apt autoremove -y && \
    rm -rf /var/lib/apt/lists/* && \
    apt clean -y

WORKDIR /workspace

# Clone the Git repository and checkout the specified commit
RUN git clone https://github.com/oobabooga/text-generation-webui && \
    cd text-generation-webui && \
    git checkout ${OOBABOOGA_COMMIT} && \
    pip3 install -U torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 && \
    pip3 install -U xformers && \
    pip3 install -U -r requirements.txt && \
    for req in extensions/*/requirements.txt ; do pip3 install -U -r "$req" ; done && \
    mkdir -p repositories && \
    cd repositories && \
    git clone https://github.com/turboderp/exllama

# Fetch the model
COPY download_model.py fetch_model.py /
RUN pip3 install -U huggingface_hub runpod && \
    /fetch_model.py ${MODEL1} /workspace/text-generation-webui/models && \
    /fetch_model.py ${MODEL2} /workspace/text-generation-webui/models && \
    /fetch_model.py ${MODEL3} /workspace/text-generation-webui/models && \
    
COPY start_standalone.sh /
COPY rp_handler.py /
COPY schemas /schemas

RUN chmod +x /start_standalone.sh

CMD ["/start_standalone.sh"]
